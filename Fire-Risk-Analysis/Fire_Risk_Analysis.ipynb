{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install category_encoders"
      ],
      "metadata": {
        "id": "VUCvJqxzJxjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9c_jpD1P2pLM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import sklearn\n",
        "\n",
        "sklearn.set_config(transform_output=\"pandas\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "qb7mYmQ32t-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fires = pd.read_csv('/content/drive/MyDrive/6201 Project/Wildfires with Weather Data 2015 to 2025 no cloudiness.csv')"
      ],
      "metadata": {
        "id": "gw8cbkWD6XRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fires"
      ],
      "metadata": {
        "id": "9yKPWEFJ6j6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of rows:\", len(fires))"
      ],
      "metadata": {
        "id": "vKcB6SUO67Qq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing_rows = fires[fires.isnull().any(axis=1)]\n",
        "print(f\"Rows with missing values: {len(missing_rows)}\")\n",
        "\n",
        "missing_per_column = fires.isnull().sum()\n",
        "print(missing_per_column)"
      ],
      "metadata": {
        "id": "BnDKdwFM7gI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fires = fires.drop(columns=[\"DISCOVERY_TIME\"])\n",
        "\n",
        "fires.to_csv(\"filtered_fires.csv\", index=False)"
      ],
      "metadata": {
        "id": "iK7SfeMU8HMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count of each fire size class\n",
        "size_class_counts = fires['FIRE_SIZE_CLASS'].value_counts().sort_index()\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(8, 5))\n",
        "size_class_counts.plot(kind='bar')\n",
        "plt.title('Distribution of Fire Size Classes (All Fires)')\n",
        "plt.xlabel('Fire Size Class')\n",
        "plt.ylabel('Number of Fires')\n",
        "plt.xticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nmDTdghCeqO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "fires['FIRE_SIZE'].hist(bins=50)\n",
        "plt.title('Distribution of Fire Sizes')\n",
        "plt.xlabel('Fire Size (acres)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "D864RAv1ysi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "fires['FIRE_SIZE'].apply(lambda x: np.log1p(x)).hist(bins=50)\n",
        "plt.title('Log-Transformed Distribution of Fire Sizes')\n",
        "plt.xlabel('log(1 + Fire Size in Acres)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OadCysm-zH_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fires_per_year = fires['FIRE_YEAR'].value_counts().sort_index()\n",
        "fires_per_year.plot(kind='bar', title='Fires Per Year', figsize=(10,5))"
      ],
      "metadata": {
        "id": "vlB8HkAY8doi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fires_by_state = fires['STATE'].value_counts()\n",
        "fires_by_state.plot(kind='bar', title='Fires by State', figsize=(12,5))"
      ],
      "metadata": {
        "id": "r7NwUmyO96Gu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.histplot(fires['DISCOVERY_DOY'], bins=52, kde=True)\n",
        "plt.title(\"Wildfire Discoveries by Day of Year\")\n",
        "plt.xlabel(\"Day of Year\")\n",
        "plt.ylabel(\"Number of Fires\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t0vBc_5t8Bc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.figure(figsize=(10,6))\n",
        "# plt.scatter(fires['LONGITUDE'], fires['LATITUDE'], alpha=0.05, s=1)\n",
        "# plt.title(\"Geographic Distribution of Wildfires\")\n",
        "# plt.xlabel(\"Longitude\")\n",
        "# plt.ylabel(\"Latitude\")\n",
        "# plt.show()\n",
        "\n",
        "# JM - added some features\n",
        "# plot\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# data\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "from matplotlib.colors import Normalize\n",
        "from matplotlib.cm import ScalarMappable\n",
        "\n",
        "# world data (Replace with your path)\n",
        "world = gpd.read_file(\n",
        "    \"ne_110m_admin_0_countries.shp\"\n",
        ")\n",
        "\n",
        "# filter on USA\n",
        "us = world[world['CONTINENT'] == 'North America']\n",
        "usa = us[us['NAME'] == 'United States of America']\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "ax.set_xlim(-170, -65)\n",
        "ax.set_ylim(24, 72)\n",
        "\n",
        "# background map\n",
        "usa.plot(ax=ax,\n",
        "         color='#88b394',\n",
        "         edgecolor='black', # colors\n",
        "         linewidth=0.5 # size and edge width\n",
        "          )\n",
        "plt.title(\"Geographic Distribution of Wildfires\")\n",
        "\n",
        "# plot eclipses\n",
        "for i,df in enumerate(fires):\n",
        "    ax.scatter(\n",
        "        fires['LONGITUDE'],\n",
        "        fires['LATITUDE'],\n",
        "        color='red',\n",
        "        s=0.01\n",
        "    )"
      ],
      "metadata": {
        "id": "1GW_LCnm8SNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.histplot(np.log(fires['FIRE_SIZE'])+1, bins=50)\n",
        "plt.title(\"Distribution of Fire Size (Log Scale)\")\n",
        "plt.xlabel(\"Log(Fire Size + 1)\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sAz8UCqa8ZXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cause_counts = fires['NWCG_GENERAL_CAUSE'].value_counts()\n",
        "\n",
        "cause_counts.plot(kind='bar', figsize=(10,5), title='Wildfires by General Cause')\n",
        "plt.xlabel(\"Cause\")\n",
        "plt.ylabel(\"Number of Fires\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ixlMJgZ_8h_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_fires = fires[fires['NWCG_GENERAL_CAUSE'].notna()]\n",
        "\n",
        "cause_by_year = filtered_fires.groupby(['FIRE_YEAR', 'NWCG_GENERAL_CAUSE']).size().unstack().fillna(0)\n",
        "\n",
        "cause_by_year.plot(kind='area', stacked=True, figsize=(12,6))\n",
        "plt.title(\"Trends in Fire Causes Over Time\")\n",
        "plt.xlabel(\"Year\")\n",
        "plt.ylabel(\"Number of Fires\")\n",
        "plt.legend(title='General Cause', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4vIpLqT-8iD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_states = fires['STATE'].value_counts().head(10)\n",
        "top_states.plot(kind='bar', title='Top 10 States by Number of Fires', figsize=(10,5))\n",
        "plt.xlabel(\"State\")\n",
        "plt.ylabel(\"Number of Fires\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "10u_u3__83VX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fires = pd.read_csv('filtered_fires.csv')\n",
        "df = fires\n",
        "\n",
        "# Count occurrences of each state within each fire size class\n",
        "fire_counts = df.groupby(['FIRE_SIZE_CLASS', 'FIRE_YEAR']).size().reset_index(name='COUNT')\n",
        "\n",
        "# Ensure we have exactly 3 top states for each fire class\n",
        "# This ensures consistent bar counts for all groups\n",
        "top_states_data = []\n",
        "fire_classes = sorted(df['FIRE_SIZE_CLASS'].unique())\n",
        "\n",
        "for fire_class in fire_classes:\n",
        "    class_data = fire_counts[fire_counts['FIRE_SIZE_CLASS'] == fire_class]\n",
        "    top3 = class_data.head(7)\n",
        "\n",
        "    # Add exactly 3 states for this class\n",
        "    for _, row in top3.iterrows():\n",
        "        top_states_data.append({\n",
        "            'FIRE_SIZE_CLASS': fire_class,\n",
        "            'FIRE_YEAR': row['FIRE_YEAR'],\n",
        "            'COUNT': row['COUNT']\n",
        "        })\n",
        "\n",
        "# Create dataframe for plotting\n",
        "plot_df = pd.DataFrame(top_states_data)\n",
        "\n",
        "# Set up the figure with a less vibrant background\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.rcParams.update({'figure.facecolor': '#f8f8f8', 'axes.facecolor': '#f8f8f8'})\n",
        "\n",
        "# Use subdued colors for the bars\n",
        "# Define a subdued color palette\n",
        "subdued_colors = [\n",
        "    '#8da290',  # muted sage green\n",
        "    '#c0a98e',  # taupe\n",
        "    '#7a94ab',  # dusty blue\n",
        "    '#9c8aa5',  # muted lavender\n",
        "    '#8b9e84',  # olive\n",
        "    '#b18e92',  # dusty rose\n",
        "    '#a0a0a0',  # gray\n",
        "    '#c9b27c',  # sand\n",
        "    '#7d929e',  # slate\n",
        "    '#94867d',  # warm gray\n",
        "    '#8e8ca3',  # dusty purple\n",
        "    '#ad9d7f'   # khaki\n",
        "]\n",
        "\n",
        "fire_classes = sorted(plot_df['FIRE_SIZE_CLASS'].unique())\n",
        "states_per_class = {}\n",
        "\n",
        "for fire_class in fire_classes:\n",
        "    class_data = plot_df[plot_df['FIRE_SIZE_CLASS'] == fire_class]\n",
        "    states_per_class[fire_class] = list(class_data['FIRE_YEAR'])\n",
        "\n",
        "# Get all unique states for coloring\n",
        "all_states = sorted(set(plot_df['FIRE_YEAR']))\n",
        "state_colors = dict(zip(all_states, subdued_colors[:len(all_states)]))\n",
        "\n",
        "# Set width and positions\n",
        "bar_width = 0.12\n",
        "index = np.arange(len(fire_classes))\n",
        "\n",
        "# Plot each state's bars\n",
        "for i, state_position in enumerate(range(7)):  # Always 3 top states\n",
        "    state_counts = []\n",
        "    state_labels = []\n",
        "\n",
        "    for fire_class in fire_classes:\n",
        "        class_data = plot_df[plot_df['FIRE_SIZE_CLASS'] == fire_class]\n",
        "        if len(class_data) > i:  # Ensure we have this position\n",
        "            row = class_data.iloc[i]\n",
        "            state_counts.append(row['COUNT'])\n",
        "            state_labels.append(row['FIRE_YEAR'])\n",
        "        else:\n",
        "            state_counts.append(0)\n",
        "            state_labels.append(None)\n",
        "\n",
        "    # Assign positions for this group of bars\n",
        "    x_positions = index - bar_width + (i * bar_width)\n",
        "\n",
        "    # Plot with consistent colors based on state name\n",
        "    for j, (count, state) in enumerate(zip(state_counts, state_labels)):\n",
        "        if state:  # Only plot if there's a state\n",
        "            plt.bar(\n",
        "                x_positions[j],\n",
        "                count,\n",
        "                width=bar_width,\n",
        "                color=state_colors[state],\n",
        "                edgecolor='white',\n",
        "                linewidth=0.5,\n",
        "                label=state if state not in plt.gca().get_legend_handles_labels()[1] else \"\"\n",
        "            )\n",
        "\n",
        "            # Add data label\n",
        "            plt.text(\n",
        "                x_positions[j],\n",
        "                count + 5,\n",
        "                f\"{int(count)}\",\n",
        "                ha='center',\n",
        "                va='bottom',\n",
        "                fontsize=10,\n",
        "                color='#505050'\n",
        "            )\n",
        "\n",
        "# Remove duplicate labels from legend\n",
        "handles, labels = plt.gca().get_legend_handles_labels()\n",
        "by_label = dict(zip(labels, handles))\n",
        "plt.legend(\n",
        "    by_label.values(),\n",
        "    by_label.keys(),\n",
        "    title='Year',\n",
        "    fontsize=12,\n",
        "    title_fontsize=14,\n",
        "    loc='upper right'\n",
        ")\n",
        "\n",
        "# Customize the plot appearance\n",
        "plt.title('Number of Fires per Year by Severity', fontsize=18, pad=20, color='#404040')\n",
        "plt.xlabel('Fire Size Class (D=Smaller to G=Largest)', fontsize=14, labelpad=10, color='#505050')\n",
        "plt.ylabel('Number of Fires', fontsize=14, labelpad=10, color='#505050')\n",
        "plt.xticks(index, fire_classes, color='#505050')\n",
        "plt.yticks(color='#505050')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.3, color='#909090')\n",
        "\n",
        "# Add a subtle border\n",
        "plt.gca().spines['top'].set_visible(False)\n",
        "plt.gca().spines['right'].set_visible(False)\n",
        "plt.gca().spines['left'].set_color('#d0d0d0')\n",
        "plt.gca().spines['bottom'].set_color('#d0d0d0')\n",
        "\n",
        "# Tighten the layout\n",
        "plt.tight_layout()\n",
        "\n",
        "# Display the figure\n",
        "plt.show()\n",
        "\n",
        "# Print numerical results\n",
        "# print(\"Top 3 States for Each Fire Size Class:\")\n",
        "# for fire_class in fire_classes:\n",
        "#     print(f\"\\nFire Size Class {fire_class}:\")\n",
        "#     class_data = plot_df[plot_df['FIRE_SIZE_CLASS'] == fire_class]\n",
        "#     for _, row in class_data.iterrows():\n",
        "#         print(f\"  {row['FIRE_YEAR']}: {int(row['COUNT'])} fires\")"
      ],
      "metadata": {
        "id": "7c02s2tJemoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fires1 = pd.read_csv('filtered_fires.csv')\n",
        "\n",
        "state_areas = {\n",
        "    'AK': 570641, 'AL': 52420, 'AR': 52035, 'AZ': 113594, 'CA': 155779,\n",
        "    'CO': 103642, 'CT': 4845,  'DE': 1949,  'FL': 53625, 'GA': 57513,\n",
        "    'HI': 6423,   'IA': 55857, 'ID': 82743, 'IL': 55584, 'IN': 35826,\n",
        "    'KS': 81814,  'KY': 39728, 'LA': 43562, 'MA': 7800,  'MD': 9775,\n",
        "    'ME': 30843,  'MI': 56804, 'MN': 79627, 'MO': 68886, 'MS': 46923,\n",
        "    'MT': 145546, 'NC': 53819, 'ND': 68976, 'NE': 76824, 'NH': 8953,\n",
        "    'NJ': 7417,   'NM': 121365,'NV': 109781,'NY': 47214, 'OH': 40861,\n",
        "    'OK': 68667,  'OR': 95988, 'PA': 44817, 'RI': 1034,  'SC': 30061,\n",
        "    'SD': 75811,  'TN': 41235, 'TX': 261232,'UT': 82170, 'VA': 39594,\n",
        "    'VT': 9249,   'WA': 66544, 'WI': 54310, 'WV': 24038, 'WY': 97093\n",
        "}\n",
        "\n",
        "area_df = pd.DataFrame(state_areas.items(), columns=['STATE', 'SQ_MILES'])\n",
        "\n",
        "fire_counts = fires1['STATE'].value_counts().reset_index()\n",
        "fire_counts.columns = ['STATE', 'FIRE_COUNT']\n",
        "\n",
        "fire_stats = pd.merge(fire_counts, area_df, on='STATE')\n",
        "fire_stats['FIRES_PER_1000_SQMI'] = fire_stats['FIRE_COUNT'] / fire_stats['SQ_MILES'] * 1000\n",
        "\n",
        "# Get top 10\n",
        "top_10_states = fire_stats.sort_values(by='FIRES_PER_1000_SQMI', ascending=False).head(10)\n",
        "\n",
        "print(top_10_states[['STATE', 'FIRE_COUNT', 'SQ_MILES', 'FIRES_PER_1000_SQMI']])\n",
        "\n",
        "top_10_states.plot(x='STATE', y='FIRES_PER_1000_SQMI', kind='bar', figsize=(10,5), title='Top 10 States by Fires per 1000 SQ Miles')"
      ],
      "metadata": {
        "id": "I-_tKyLTyKRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fires = pd.read_csv('filtered_fires.csv')"
      ],
      "metadata": {
        "id": "NknPZxMWkwGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nc_fires = pd.read_csv('filtered_fires.csv')\n",
        "\n",
        "nc_firess = nc_fires[nc_fires['STATE'] == 'NC'].copy()\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "nc_fires['FIRE_SIZE'].hist(bins=40)\n",
        "plt.title(\"Distribution of Fire Sizes in NC\")\n",
        "plt.xlabel(\"Fire Size (acres)\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "np.log(nc_fires['FIRE_SIZE']+1).hist(bins=40)\n",
        "plt.title(\"Log-Transformed Fire Size Distribution in NC\")\n",
        "plt.xlabel(\"log(1 + Fire Size)\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "HNgtjpnVSaFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fires_per_year = nc_fires['FIRE_YEAR'].value_counts().sort_index()\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(10, 5))\n",
        "fires_per_year.plot(kind='bar')\n",
        "plt.title('Wildfires in North Carolina by Year')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Number of Fires')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZFX1ONWFT1Ty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cause_counts = nc_fires['NWCG_GENERAL_CAUSE'].dropna().value_counts()\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(8, 5))\n",
        "cause_counts.plot(kind='bar')\n",
        "plt.title('Wildfires in NC by Cause Classification')\n",
        "plt.xlabel('Cause Classification')\n",
        "plt.ylabel('Number of Fires')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "baZFnryQT3Gc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Build"
      ],
      "metadata": {
        "id": "o2GHG8KEg4E1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import statsmodels.api as sm"
      ],
      "metadata": {
        "id": "swPph854h0SY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fires = pd.read_csv('/content/drive/MyDrive/6201 Project/Wildfires with Weather Data 2015 to 2025 no cloudiness.csv')\n",
        "\n",
        "fires.columns"
      ],
      "metadata": {
        "id": "bDETLDZH9ykr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6,2))\n",
        "nc_fires['Precipitation_Total'].hist(bins=40)\n",
        "plt.title(\"Distribution of Precipitation_Total\")\n",
        "plt.xlabel(\"Fire Size (acres)\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(6,2))\n",
        "nc_fires['Cloudiness_Average'].hist(bins=20)\n",
        "plt.title(\"Distribution of Cloudiness Averages\")\n",
        "plt.xlabel(\"Cloudiness Average (Whole Number Percentage)\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(6,2))\n",
        "nc_fires['Temperature_Average'].hist(bins=40)\n",
        "plt.title(\"Distribution of Temperature Averages\")\n",
        "plt.xlabel(\"Average Temperature\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(6,2))\n",
        "nc_fires['Temperature_Max'].hist(bins=40)\n",
        "plt.title(\"Distribution of Temperature Maximums\")\n",
        "plt.xlabel(\"Maximum Temperature\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6_w9DraqayB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Label target column\n",
        "fires['LARGE_FIRE'] = fires['FIRE_SIZE_CLASS'].isin(['F', 'G']).astype(int)\n",
        "\n",
        "#conversion to datetime\n",
        "fires['DISCOVERY_DATE'] = pd.to_datetime(fires['DISCOVERY_DATE'], errors='coerce')\n",
        "\n",
        "#create month column\n",
        "fires['DISCOVERY_MONTH'] = fires['DISCOVERY_DATE'].dt.month"
      ],
      "metadata": {
        "id": "wPmwzoybg1b3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = ['DISCOVERY_MONTH',\n",
        "            'NWCG_GENERAL_CAUSE',\n",
        "            'Precipitation_Total',\n",
        "            'Temperature_Average',\n",
        "            'Cloudiness_Average',\n",
        "            'Temperature_Max']\n",
        "target = 'LARGE_FIRE'"
      ],
      "metadata": {
        "id": "reZS9LKjg9D1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = fires[features]\n",
        "y = fires[target]\n",
        "\n",
        "# Preprocessing\n",
        "categorical = ['NWCG_GENERAL_CAUSE', 'DISCOVERY_MONTH']\n",
        "numeric = ['Precipitation_Total', 'Temperature_Average', 'Cloudiness_Average', 'Temperature_Max']\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical),\n",
        "    ('num', StandardScaler(), numeric)  # scale numeric columns\n",
        "])\n",
        "\n",
        "lg_model = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', LogisticRegression(max_iter=5000))\n",
        "])\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
        "\n",
        "# Fit and predict\n",
        "lg_model.fit(X_train, y_train)\n",
        "y_pred = lg_model.predict(X_test)"
      ],
      "metadata": {
        "id": "pxND2JyaiEkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "JAUbMfRKiII2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imbalanced Data Issue - trying random forest below"
      ],
      "metadata": {
        "id": "MQx40_nYkfBO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_model = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', RandomForestClassifier(\n",
        "        n_estimators=100,\n",
        "        class_weight='balanced',  # handles class imbalance\n",
        "        random_state=42\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Train/test split\n",
        "X = fires[features]\n",
        "y = fires[target]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
        "\n",
        "# Train and predict\n",
        "rf_model.fit(X_train, y_train)\n",
        "y_pred = rf_model.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "zSvaAj9jjoNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# feature performance\n",
        "\n",
        "# Access the Random Forest model from the pipeline\n",
        "rf_modell = rf_model.named_steps['classifier']\n",
        "\n",
        "# Get the OneHotEncoder from the preprocessor\n",
        "ohe = rf_model.named_steps['preprocessor'].named_transformers_['cat']\n",
        "\n",
        "# Get feature names from one-hot encoded categorical features\n",
        "encoded_cat_names = ohe.get_feature_names_out(categorical)\n",
        "\n",
        "# Combine with numeric feature names\n",
        "feature_names = list(encoded_cat_names) + numeric\n",
        "\n",
        "# Get feature importances\n",
        "importances = rf_modell.feature_importances_\n",
        "indices = sorted(range(len(importances)), key=lambda i: importances[i], reverse=True)\n",
        "\n",
        "# Plot top features\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar([feature_names[i] for i in indices[:10]], [importances[i] for i in indices[:10]])\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.title(\"Top 10 Feature Importances\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Q_dGLwadlXsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter to only large fires (from model logic or class F/G)\n",
        "large_fires = fires[fires['FIRE_SIZE_CLASS'].isin(['F', 'G'])]\n",
        "\n",
        "# Then group by location\n",
        "top_large_locations = large_fires.groupby(['LATITUDE', 'LONGITUDE']).size().reset_index(name='count')\n",
        "top_10_large_locations = top_large_locations.sort_values(by='count', ascending=False).head(10)\n",
        "\n",
        "print(top_10_large_locations)"
      ],
      "metadata": {
        "id": "Z5rN46X_u64g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_avg_size = large_fires.groupby(['LATITUDE', 'LONGITUDE'])['FIRE_SIZE'].mean().reset_index(name='avg_fire_size')\n",
        "top_10_avg = top_avg_size.sort_values(by='avg_fire_size', ascending=False).head(10)\n",
        "\n",
        "print(top_10_avg)"
      ],
      "metadata": {
        "id": "gkTfjvJpvaLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now attempting logistic regression to asses largest determinents for any fire"
      ],
      "metadata": {
        "id": "rOcRzXfvmTVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "import numpy as np\n",
        "\n",
        "# Columns to use\n",
        "cols = ['FIRE_SIZE', 'Precipitation_Total', 'Temperature_Average', 'Cloudiness_Average', 'Temperature_Max']\n",
        "\n",
        "# Drop rows with missing values\n",
        "df_clean = fires[cols].dropna()\n",
        "\n",
        "# Combine all features\n",
        "X = df_clean[['Precipitation_Total', 'Temperature_Average', 'Cloudiness_Average', 'Temperature_Max']]\n",
        "\n",
        "# Target variable\n",
        "y = df_clean['FIRE_SIZE']\n",
        "\n",
        "# Final cleaning: ensure all columns are numeric\n",
        "X = X.apply(pd.to_numeric, errors='coerce')\n",
        "y = pd.to_numeric(y, errors='coerce')\n",
        "\n",
        "# Drop rows with any NaNs\n",
        "X, y = X.align(y, join='inner', axis=0)\n",
        "X = X.dropna()\n",
        "y = y.loc[X.index]\n",
        "\n",
        "# Add intercept and convert to float\n",
        "X = sm.add_constant(X).astype(float)\n",
        "y = y.astype(float)\n",
        "\n",
        "# Fit model\n",
        "model = sm.OLS(y, X)\n",
        "results = model.fit()\n",
        "\n",
        "# View results\n",
        "print(results.summary())"
      ],
      "metadata": {
        "id": "BhdUr-2Vprdw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = fires.copy()\n",
        "# find numerical variables\n",
        "# numerical = [var for var in fires.columns if fires[var].dtype!='O']\n",
        "# print('There are {} numerical variables\\n'.format(len(numerical)))\n",
        "# print('The numerical variables are :', numerical)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df.drop(['FIPS',\n",
        "             'FOD_ID',\n",
        "             'DISCOVERY_DOY',\n",
        "             'DISCOVERY_TIME',\n",
        "             'DISCOVERY_DATE',\n",
        "             'LATITUDE',\n",
        "             'LONGITUDE',\n",
        "             'FIPS_CODE',\n",
        "             'ID',\n",
        "             'FIPS',\n",
        "             'Filtered_fires_County',\n",
        "             'CONT_DATE',\n",
        "             'STATE',\n",
        "             'NOAA_Climate_Data_combined_County',\n",
        "             'Date'],\n",
        "             axis=1)\n",
        "\n",
        "y = df['FIRE_SIZE']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
        "\n",
        "# # check the shape of X_train and X_test\n",
        "# categorical = [col for col in X_train.columns if X_train[col].dtypes == 'O']\n",
        "# print(categorical)\n",
        "# numerical = [col for col in X_train.columns if X_train[col].dtypes != 'O']\n",
        "# # print(numerical)\n",
        "\n",
        "# encode RainToday variable\n",
        "\n",
        "import category_encoders as ce\n",
        "\n",
        "encoder = ce.BinaryEncoder(cols=['NWCG_CAUSE_CLASSIFICATION', 'NWCG_GENERAL_CAUSE', 'FIRE_SIZE_CLASS'])\n",
        "\n",
        "X_train = encoder.fit_transform(X_train)\n",
        "\n",
        "X_test = encoder.transform(X_test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# train a logistic regression model on the training set\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "# instantiate the model\n",
        "logreg = LogisticRegression(solver='liblinear', random_state=0)\n",
        "\n",
        "\n",
        "# fit the model\n",
        "# logreg.fit(X_train, y_train)\n",
        "\n",
        "X_train.head()"
      ],
      "metadata": {
        "id": "hoS3DZmm8EdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "my_headers = {'token' : 'QKnPTjSfJLNAbQnBiGgzXaarAtljJMyB'}\n",
        "response = requests.get('https://www.ncdc.noaa.gov/cdo-web/api/v2/datatypes', headers=my_headers)\n",
        "print(response.json())"
      ],
      "metadata": {
        "id": "wz9f38net-av"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}